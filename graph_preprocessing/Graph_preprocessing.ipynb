{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph pre-process\n",
    "Please note, this is created specifically for Vienna, other cities may have to be processed differently in regard to elevation data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:26:01.137857Z",
     "start_time": "2025-07-06T19:25:58.892922Z"
    }
   },
   "source": [
    "#Setup:\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T19:26:01.151621Z",
     "start_time": "2025-07-06T19:26:01.148911Z"
    }
   },
   "source": [
    "city = \"Vienna, Austria\" # making this a variable, since it needed for the features module "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T21:57:25.716993Z",
     "start_time": "2025-06-02T21:57:25.658919Z"
    }
   },
   "source": [
    "G = ox.graph.graph_from_place(city, network_type=\"walk\") # getting the graph of walking paths in Vienna \n",
    "#Creating a subgraph of nodes that have the streetcount as 2 or higher\n",
    "\n",
    "selected_nodes = [n for n, attr in G.nodes(data=True) if attr.get('street_count', 0) > 1]\n",
    "\n",
    "SG = G.subgraph(selected_nodes)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Nominatim did not geocode query 'Vienna, Austria' to a geometry of type (Multi)Polygon.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/osmnx/geocoder.py:173\u001B[0m, in \u001B[0;36m_geocode_query_to_gdf\u001B[0;34m(query, which_result, by_osmid)\u001B[0m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 173\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_get_first_polygon\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/osmnx/geocoder.py:239\u001B[0m, in \u001B[0;36m_get_first_polygon\u001B[0;34m(results)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;66;03m# if we never found a polygon, raise an error\u001B[39;00m\n\u001B[0;32m--> 239\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m\n",
      "\u001B[0;31mTypeError\u001B[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m G \u001B[38;5;241m=\u001B[39m \u001B[43mox\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgraph_from_place\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnetwork_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwalk\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# getting the graph of walking paths in Vienna \u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#Creating a subgraph of nodes that have the streetcount as 2 or higher\u001B[39;00m\n\u001B[1;32m      4\u001B[0m selected_nodes \u001B[38;5;241m=\u001B[39m [n \u001B[38;5;28;01mfor\u001B[39;00m n, attr \u001B[38;5;129;01min\u001B[39;00m G\u001B[38;5;241m.\u001B[39mnodes(data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mif\u001B[39;00m attr\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstreet_count\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m0\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/osmnx/graph.py:386\u001B[0m, in \u001B[0;36mgraph_from_place\u001B[0;34m(query, network_type, simplify, retain_all, truncate_by_edge, which_result, custom_filter)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;124;03mDownload and create a graph within the boundaries of some place(s).\u001B[39;00m\n\u001B[1;32m    320\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;124;03mdocumentation for caveats.\u001B[39;00m\n\u001B[1;32m    384\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;66;03m# extract the geometry from the GeoDataFrame to use in query\u001B[39;00m\n\u001B[0;32m--> 386\u001B[0m polygon \u001B[38;5;241m=\u001B[39m \u001B[43mgeocoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgeocode_to_gdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhich_result\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhich_result\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39munion_all()\n\u001B[1;32m    387\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConstructed place geometry polygon(s) to query Overpass\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    388\u001B[0m utils\u001B[38;5;241m.\u001B[39mlog(msg, level\u001B[38;5;241m=\u001B[39mlg\u001B[38;5;241m.\u001B[39mINFO)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/osmnx/geocoder.py:125\u001B[0m, in \u001B[0;36mgeocode_to_gdf\u001B[0;34m(query, which_result, by_osmid)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# geocode each query, concat as GeoDataFrame rows, then set the CRS\u001B[39;00m\n\u001B[1;32m    124\u001B[0m results \u001B[38;5;241m=\u001B[39m (_geocode_query_to_gdf(q, wr, by_osmid) \u001B[38;5;28;01mfor\u001B[39;00m q, wr \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(q_list, wr_list))\n\u001B[0;32m--> 125\u001B[0m gdf \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresults\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mset_crs(settings\u001B[38;5;241m.\u001B[39mdefault_crs)\n\u001B[1;32m    127\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreated GeoDataFrame with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(gdf)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m rows from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(q_list)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m queries\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    128\u001B[0m utils\u001B[38;5;241m.\u001B[39mlog(msg, level\u001B[38;5;241m=\u001B[39mlg\u001B[38;5;241m.\u001B[39mINFO)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/pandas/core/reshape/concat.py:382\u001B[0m, in \u001B[0;36mconcat\u001B[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m copy \u001B[38;5;129;01mand\u001B[39;00m using_copy_on_write():\n\u001B[1;32m    380\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 382\u001B[0m op \u001B[38;5;241m=\u001B[39m \u001B[43m_Concatenator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    384\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    385\u001B[0m \u001B[43m    \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjoin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    388\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverify_integrity\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverify_integrity\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m op\u001B[38;5;241m.\u001B[39mget_result()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/pandas/core/reshape/concat.py:445\u001B[0m, in \u001B[0;36m_Concatenator.__init__\u001B[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001B[0m\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverify_integrity \u001B[38;5;241m=\u001B[39m verify_integrity\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy \u001B[38;5;241m=\u001B[39m copy\n\u001B[0;32m--> 445\u001B[0m objs, keys \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_clean_keys_and_objs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;66;03m# figure out what our result ndim is going to be\u001B[39;00m\n\u001B[1;32m    448\u001B[0m ndims \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_ndims(objs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/pandas/core/reshape/concat.py:504\u001B[0m, in \u001B[0;36m_Concatenator._clean_keys_and_objs\u001B[0;34m(self, objs, keys)\u001B[0m\n\u001B[1;32m    502\u001B[0m     objs_list \u001B[38;5;241m=\u001B[39m [objs[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m keys]\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 504\u001B[0m     objs_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mobjs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(objs_list) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    507\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo objects to concatenate\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/osmnx/geocoder.py:124\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# geocode each query, concat as GeoDataFrame rows, then set the CRS\u001B[39;00m\n\u001B[0;32m--> 124\u001B[0m results \u001B[38;5;241m=\u001B[39m (\u001B[43m_geocode_query_to_gdf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mby_osmid\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m q, wr \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(q_list, wr_list))\n\u001B[1;32m    125\u001B[0m gdf \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mconcat(results, ignore_index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mset_crs(settings\u001B[38;5;241m.\u001B[39mdefault_crs)\n\u001B[1;32m    127\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreated GeoDataFrame with \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(gdf)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m rows from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(q_list)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m queries\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/thesis_runningRoutes/lib/python3.12/site-packages/osmnx/geocoder.py:176\u001B[0m, in \u001B[0;36m_geocode_query_to_gdf\u001B[0;34m(query, which_result, by_osmid)\u001B[0m\n\u001B[1;32m    174\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    175\u001B[0m         msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNominatim did not geocode query \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m to a geometry of type (Multi)Polygon.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 176\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(results) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m which_result:\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;66;03m# else, if we got at least which_result results, choose that one\u001B[39;00m\n\u001B[1;32m    180\u001B[0m     result \u001B[38;5;241m=\u001B[39m results[which_result \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m]\n",
      "\u001B[0;31mTypeError\u001B[0m: Nominatim did not geocode query 'Vienna, Austria' to a geometry of type (Multi)Polygon."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projecting the graph so it alligns with the StadtWien elevation data\n",
    "SG_proj = ox.projection.project_graph(SG, to_crs = 31256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sofiiashome/Documents/Studying at WU/Bachelor's Thesis/Elevation tifs2/15_2_dgm.tif\n"
     ]
    }
   ],
   "source": [
    "# Adding paths to our elevation files\n",
    "raster_path_names = ['15_2_dgm.tif', '24_4_dgm.tif', '45_3_dgm.tif', '56_1_dgm.tif', '34_2_dgm.tif', '38_1_dgm.tif', '47_4_dgm.tif', '26_3_dgm.tif', '53_4_dgm.tif', '48_3_dgm.tif', '57_2_dgm.tif', '35_1_dgm.tif', '43_2_dgm.tif', '26_2_dgm.tif', '32_2_dgm.tif', '44_1_dgm.tif', '17_4_dgm.tif', '36_4_dgm.tif', '22_4_dgm.tif', '43_3_dgm.tif', '27_1_dgm.tif', '15_3_dgm.tif', '45_2_dgm.tif', '33_1_dgm.tif', '34_3_dgm.tif', '55_4_dgm.tif', '25_4_dgm.tif', '44_3_dgm.tif', '35_2_dgm.tif', '43_1_dgm.tif', '57_1_dgm.tif', '33_3_dgm.tif', '46_4_dgm.tif', '27_3_dgm.tif', '42_2_dgm.tif', '34_1_dgm.tif', '56_2_dgm.tif', '45_1_dgm.tif', '16_4_dgm.tif', '27_2_dgm.tif', '23_4_dgm.tif', '38_3_dgm.tif', '56_3_dgm.tif', '37_4_dgm.tif', '44_2_dgm.tif', '48_1_dgm.tif', '26_1_dgm.tif', '35_3_dgm.tif', '54_4_dgm.tif', '58_2_dgm.tif', '54_1_dgm.tif', '36_2_dgm.tif', '32_4_dgm.tif', '53_3_dgm.tif', '48_4_dgm.tif', '47_3_dgm.tif', '26_4_dgm.tif', '55_2_dgm.tif', '37_1_dgm.tif', '16_1_dgm.tif', '24_3_dgm.tif', '45_4_dgm.tif', '34_4_dgm.tif', '55_3_dgm.tif', '24_2_dgm.tif', '15_4_dgm.tif', '46_1_dgm.tif', '43_4_dgm.tif', '36_3_dgm.tif', '25_1_dgm.tif', '17_3_dgm.tif', '53_2_dgm.tif', '47_2_dgm.tif', '37_2_dgm.tif', '55_1_dgm.tif', '46_3_dgm.tif', '27_4_dgm.tif', '33_4_dgm.tif', '16_2_dgm.tif', '28_3_dgm.tif', '36_1_dgm.tif', '54_2_dgm.tif', '58_1_dgm.tif', '25_3_dgm.tif', '44_4_dgm.tif', '35_4_dgm.tif', '54_3_dgm.tif', '47_1_dgm.tif', '25_2_dgm.tif', '53_1_dgm.tif', '56_4_dgm.tif', '37_3_dgm.tif', '23_3_dgm.tif', '42_4_dgm.tif', '46_2_dgm.tif', '24_1_dgm.tif', '16_3_dgm.tif', '33_2_dgm.tif']\n",
    "raster_paths = [\"/Users/sofiiashome/Documents/Studying at WU/Bachelor's Thesis/Bachelor Thesis Coding/LoopBuddy/graph_preprocessing/Elevation tifs/\"+x for x in raster_path_names]\n",
    "print(raster_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": "SG_proj = ox.elevation.add_node_elevations_raster(SG_proj, raster_paths, cpus = 1) #Adds elevations from local raster files"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's add more node labels.\n",
    "\n",
    "Here we add: stoplights, pavement type, stairs\n",
    "\n",
    "Relevant tag links:\n",
    "\n",
    "Stoplights: https://wiki.openstreetmap.org/wiki/Tag:highway%3Dtraffic_signals\n",
    "\n",
    "Pavement type: https://wiki.openstreetmap.org/wiki/Key:surface\n",
    "\n",
    "Stairs :  https://wiki.openstreetmap.org/wiki/Tag:highway%3Dsteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_unproj = ox.projection.project_graph(SG_proj, to_crs = 4326) # Projecting back to EPSD: 4326, as this is the CRS that OSMnx and OSM (data) # https://wiki.openstreetmap.org/wiki/Converting_to_WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the stoplight data\n",
    "tags = {\"highway\":  \"steps\", \"surface\": True }#\"surface\": True ,\"highway\":\"steps\"\n",
    "\n",
    "loaded_features = ox.features.features_from_place(city, tags) # getting the stoplight data from OSM \n",
    "# https://wiki.openstreetmap.org/wiki/Tag:highway%3Dtraffic_signals\n",
    "\n",
    "# print(loaded_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     381234      392321     1438521 ...    25277154 11565229497\n",
      "  6020323414]\n"
     ]
    }
   ],
   "source": [
    "# attaching it to the nearest nodes as attributes # code sources from \"16-download-osm-geospatial-features.ipynb\" in the OSMnx examples gallery\n",
    "feature_points = loaded_features.representative_point()\n",
    "nearest_nodes = ox.distance.nearest_nodes(SG_unproj, feature_points.x, feature_points.y)\n",
    "\n",
    "print(nearest_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting stoplights,stairs to False for all nodes for consistency reasons\n",
    "# Create a dict: {node_id: False for all nodes}\n",
    "false_dict = {node: False for node in SG_unproj.nodes}\n",
    "\n",
    "# Batch update\n",
    "nx.set_node_attributes(SG_unproj, false_dict, \"stoplights\")\n",
    "nx.set_node_attributes(SG_unproj, false_dict, \"steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to get the surfaces to paved vs not paved, we need to group the tags into what we considered paved vs not paved:\n",
    "paved = [\n",
    "    'paved', 'asphalt', 'chipseal', 'concrete', 'concrete:lanes', 'concrete:plates',\n",
    "    'paving_stones', 'paving_stones:lanes', 'grass_paver', 'sett', 'unhewn_cobblestone',\n",
    "    'cobblestone', 'cobblestone:flattened', 'bricks', 'metal', 'metal_grid', 'wood',\n",
    "    'rubber', 'tiles', 'fibre_reinforced_polymer_grate', 'artificial_turf', 'acrylic',\n",
    "    'carpet', 'plastic', 'tartan','stepping_stones'\n",
    "]\n",
    "\n",
    "unpaved = [\n",
    "    'unpaved', 'compacted', 'fine_gravel', 'gravel', 'shells', 'rock', 'pebblestone',\n",
    "    'ground', 'dirt', 'earth', 'grass', 'mud', 'sand', 'woodchips', 'snow', 'ice',\n",
    "    'salt', 'clay'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning why I am doing this, and not just using the already present highway tag, is because this tags the stoplights more correctly, and on each node that they are present on\n",
    "\n",
    "# in these and the following functions we use get is because it avoid issues if the attribute is empty\n",
    "\n",
    "leftover_null_nodes = []\n",
    "\n",
    "useful_tags = [\"steps\", \"surface\"]\n",
    "for node, feature in zip(nearest_nodes, loaded_features[useful_tags].to_dict(orient=\"records\")): # here we only update the nodes that have stoplights (that's why we had to add the False values beforehand)    \n",
    "    #Adding pavement info:\n",
    "    if feature.get(\"surface\") in paved:\n",
    "        surface_state = \"paved\"\n",
    "    elif feature.get(\"surface\") in unpaved:\n",
    "        surface_state = \"unpaved\"\n",
    "    else: # handling null values by getting the vaue from adjacent nodes\n",
    "\n",
    "        neighbor_surfaces = []\n",
    "        for neighbor in SG_unproj.adj[node]: # checks neighbor surfaces\n",
    "            neighbor_surface = SG_unproj.nodes[neighbor].get(\"surface\")\n",
    "            if neighbor_surface in paved:\n",
    "                neighbor_surfaces.append(\"paved\")\n",
    "            elif neighbor_surface in unpaved:\n",
    "                neighbor_surfaces.append(\"unpaved\")\n",
    "        \n",
    "        if neighbor_surfaces:\n",
    "            # Majority vote: pick most common\n",
    "            surface_state = max(set(neighbor_surfaces), key=neighbor_surfaces.count)\n",
    "        else:\n",
    "            # Fallback if no neighbors have surface info:\n",
    "            surface_state = \"unknown\"\n",
    "            leftover_null_nodes.append(node)\n",
    "\n",
    "\n",
    "    SG_unproj.nodes[node].update({\"surface\":surface_state})\n",
    "\n",
    "    # Adding steps info:\n",
    "    is_step = feature.get(\"steps\") == \"yes\"\n",
    "    SG_unproj.nodes[node].update({\"steps\": is_step})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, remaining nodes: 1673\n",
      "Iteration 1, remaining nodes: 1109\n",
      "Iteration 2, remaining nodes: 1073\n",
      "Iteration 3, remaining nodes: 1062\n",
      "Iteration 4, remaining nodes: 1060\n",
      "Iteration 5, remaining nodes: 1058\n",
      "Iteration 6, remaining nodes: 1056\n",
      "No more updates possible, stopping recursion.\n"
     ]
    }
   ],
   "source": [
    "iterations = 0\n",
    "max_iterations = 1000  # safety net\n",
    "\n",
    "while len(leftover_null_nodes) > 0 and iterations <= max_iterations: # loops over all the nodes again and again until \"theoretically\" there are no unlabelled nodes. Uses the logic that adjacent nodes have similar paving. \n",
    "\n",
    "    print(f\"Iteration {iterations}, remaining nodes: {len(leftover_null_nodes)}\")\n",
    "    nodes_updated_this_pass = [] # to ensure at least some nodes got filled\n",
    "\n",
    "\n",
    "    for node in leftover_null_nodes: \n",
    "        neighbor_surfaces = []\n",
    "        for neighbor in SG_unproj.adj[node]: # checks neighbor surfaces\n",
    "            neighbor_surface = SG_unproj.nodes[neighbor].get(\"surface\")\n",
    "            #print(f\"Neighbor {neighbor} surface: {neighbor_surface}\")\n",
    "            #print(neighbor_surface)\n",
    "            if neighbor_surface in paved:\n",
    "                neighbor_surfaces.append(\"paved\")\n",
    "            elif neighbor_surface in unpaved:\n",
    "                neighbor_surfaces.append(\"unpaved\")\n",
    "        #print(neighbor_surfaces)\n",
    "\n",
    "        if neighbor_surfaces:\n",
    "        # picking most common nodes\n",
    "            surface_state = max(set(neighbor_surfaces), key=neighbor_surfaces.count)\n",
    "            SG_unproj.nodes[node].update({\"surface\": surface_state})\n",
    "            nodes_updated_this_pass.append(node)\n",
    "        else:\n",
    "        #if no neighbors have surface info\n",
    "            surface_state = \"unknown\"  \n",
    "\n",
    "    for node in nodes_updated_this_pass:\n",
    "        leftover_null_nodes.remove(node)\n",
    "\n",
    "    if not nodes_updated_this_pass: # to avoid the situation where isolated clusters keep the loop running\n",
    "                print(\"No more updates possible, stopping recursion.\")\n",
    "                break\n",
    "    \n",
    "    iterations += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For some reason the stoplights break if you load them with everything, so here we go:\n",
    "\n",
    "stoplights = ox.features.features_from_place(city, {\"highway\": \"traffic_signals\"}) # getting the stoplight data from OSM \n",
    "stoplights_points = stoplights.representative_point()\n",
    "nn_stoplights = ox.distance.nearest_nodes(SG_unproj, stoplights_points.x, stoplights_points.y)\n",
    "\n",
    "for node, feature in zip(nn_stoplights, stoplights[[\"highway\"]].to_dict(orient=\"records\")):\n",
    "    is_stoplight = feature.get(\"highway\") == \"traffic_signals\"\n",
    "    SG_unproj.nodes[node].update({\"stoplights\": is_stoplight})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Adding edge values for parametres: stoplights, pavements, steps\n",
    "Basically the logic goes, that if if the edge's nodes have these things in one or other state, the edge should inherit that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node0, node1, key in SG_unproj.edges(keys=True):\n",
    "    # Stoplights\n",
    "    if (SG_unproj.nodes[node0].get(\"stoplights\") == True) or (SG_unproj.nodes[node1].get(\"stoplights\") == True):\n",
    "        SG_unproj.edges[node0, node1, key][\"stoplights\"] = True\n",
    "    else:\n",
    "        SG_unproj.edges[node0, node1, key][\"stoplights\"] = False\n",
    "\n",
    "    # Steps\n",
    "    if (SG_unproj.nodes[node0].get(\"steps\") == True) or (SG_unproj.nodes[node1].get(\"steps\") == True):\n",
    "        SG_unproj.edges[node0, node1, key][\"steps\"] = True\n",
    "    else:\n",
    "        SG_unproj.edges[node0, node1, key][\"steps\"] = False\n",
    "\n",
    "    # Pavement:\n",
    "    # now here, we have to think actually: the adjacent to the edge nodes might have different statuses\n",
    "\n",
    "    # logic: \n",
    "        # if both the same -> that label\n",
    "        # if diff or unknown -> unknown\n",
    "            # because then we can apply a partial punishment to the unknown nodes, since in reality we don't know how much of the edge is which pavement type\n",
    "    if SG_unproj.nodes[node0].get(\"surface\") == SG_unproj.nodes[node1].get(\"surface\"):\n",
    "        SG_unproj.edges[node0, node1, key][\"surface\"] = SG_unproj.nodes[node0].get(\"surface\")\n",
    "    else:\n",
    "        SG_unproj.edges[node0, node1, key][\"surface\"] = \"unknown\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing edge speeds and calculate edge travel times with the speed module\n",
    "SG_unproj = ox.routing.add_edge_speeds(SG_unproj)\n",
    "SG_unproj = ox.routing.add_edge_travel_times(SG_unproj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing pickl\n",
    "import pickle\n",
    "graph_path = \"/Users/sofiiashome/Documents/Studying at WU/Bachelor's Thesis/GraphSaves/Weighted1_9.pkl\"\n",
    "with open(graph_path, \"wb\") as f:\n",
    "    pickle.dump(SG_unproj, f)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Code used to process the original data into Float32 files, however the process may have to be toggled to your specific file format:\n",
    "Original files with elevation data can be downloaded from: https://www.wien.gv.at/ma41datenviewer/public/\n",
    "They were not included due to size"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import rasterio\n",
    "# import os\n",
    "\n",
    "\n",
    "# raster_paths = [\"\"] # Directory with the files to be converted\n",
    "\n",
    "# # Output directory for converted files:\n",
    "# output_dir = \"\"\n",
    "# os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "# # Process each file\n",
    "# for tif_file in raster_paths:\n",
    "#     try:\n",
    "#         # Construct output filename:\n",
    "#         file_name = os.path.basename(tif_file)\n",
    "#         output_file = os.path.join(output_dir, file_name)\n",
    "\n",
    "#         # Convert raster to Float32:\n",
    "#         with rasterio.open(tif_file) as src:\n",
    "#             data = src.read(1).astype(\"float32\")  # Convert to Float32\n",
    "#             profile = src.profile\n",
    "#             profile.update(dtype=\"float32\")\n",
    "\n",
    "#             with rasterio.open(output_file, \"w\", **profile) as dst:\n",
    "#                 dst.write(data, 1)\n",
    "\n",
    "#         print(f\"Converted: {tif_file} -> {output_file}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error processing {tif_file}: {e}\")\n",
    "\n",
    "# print(\"Conversion completed!\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import os\n",
    "# \n",
    "# raster_paths = [\"\"]\n",
    "# if os.path.exists(raster_paths[0]):\n",
    "#     print(\"File exists!\")\n",
    "# else:\n",
    "#     print(\"File NOT found! Check the path.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_runningRoutes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
